{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1zLXSe4c5YN0xD7wEjBAAooUGCWcj-F19",
      "authorship_tag": "ABX9TyMUV+Ck0pOSoih7dV2a9EHk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NishantMD/Echelon-25/blob/main/OCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg_ui95Zm8DX",
        "outputId": "53d20e51-f365-4569-8ef7-4c767ecd6125"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting easyocr\n",
            "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.20.1+cu124)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from easyocr) (4.11.0.86)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from easyocr) (1.13.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.25.2)\n",
            "Collecting python-bidi (from easyocr)\n",
            "  Downloading python_bidi-0.6.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from easyocr) (6.0.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.0.7)\n",
            "Collecting pyclipper (from easyocr)\n",
            "  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from easyocr)\n",
            "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->easyocr)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->easyocr)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->easyocr)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->easyocr)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->easyocr)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->easyocr)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->easyocr)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->easyocr)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->easyocr)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->easyocr)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->easyocr) (1.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (2025.2.18)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->easyocr) (3.0.2)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (292 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.9/292.9 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-bidi, pyclipper, pytesseract, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, easyocr\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed easyocr-1.7.2 ninja-1.11.1.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyclipper-1.3.0.post6 pytesseract-0.3.13 python-bidi-0.6.6\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python pytesseract easyocr\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdf2image\n",
        "!apt-get install poppler-utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtbQ47crIaK8",
        "outputId": "efd96295-8d57-46fb-f3b6-b373ee2909f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pdf2image) (11.1.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.6 [186 kB]\n",
            "Fetched 186 kB in 0s (407 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 124947 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.6_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.6) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.6) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir('OCRimages'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLHivT8wLTJZ",
        "outputId": "84922bfc-258b-4546-99ed-5d2f45f148ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "\n",
        "pages = convert_from_path('/content/Test.pdf', dpi=300)\n",
        "print(f\"Pages detected: {len(pages)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHL8gaKuMcDj",
        "outputId": "ee1c9501-6ee9-467f-8963-c900652ffe95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pages detected: 33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pdf2image import convert_from_path\n",
        "\n",
        "pdf_path = '/content/Test.pdf'\n",
        "output_folder = 'OCRimages'\n",
        "\n",
        "# Create folder if not exists\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Convert PDF to images\n",
        "pages = convert_from_path(pdf_path, dpi=300)\n",
        "print(f\"Pages detected: {len(pages)}\")\n",
        "\n",
        "# Save images with debug statements\n",
        "for i, page in enumerate(pages):\n",
        "    image_path = f\"{output_folder}/page_{i + 1}.png\"\n",
        "    try:\n",
        "        page.save(image_path, 'PNG')\n",
        "        print(f\"✅ Saved: {image_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to save {image_path}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DT8h4WdM0MU",
        "outputId": "4c61d035-4e96-4589-fbd9-45b8e6cb22fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pages detected: 33\n",
            "✅ Saved: OCRimages/page_1.png\n",
            "✅ Saved: OCRimages/page_2.png\n",
            "✅ Saved: OCRimages/page_3.png\n",
            "✅ Saved: OCRimages/page_4.png\n",
            "✅ Saved: OCRimages/page_5.png\n",
            "✅ Saved: OCRimages/page_6.png\n",
            "✅ Saved: OCRimages/page_7.png\n",
            "✅ Saved: OCRimages/page_8.png\n",
            "✅ Saved: OCRimages/page_9.png\n",
            "✅ Saved: OCRimages/page_10.png\n",
            "✅ Saved: OCRimages/page_11.png\n",
            "✅ Saved: OCRimages/page_12.png\n",
            "✅ Saved: OCRimages/page_13.png\n",
            "✅ Saved: OCRimages/page_14.png\n",
            "✅ Saved: OCRimages/page_15.png\n",
            "✅ Saved: OCRimages/page_16.png\n",
            "✅ Saved: OCRimages/page_17.png\n",
            "✅ Saved: OCRimages/page_18.png\n",
            "✅ Saved: OCRimages/page_19.png\n",
            "✅ Saved: OCRimages/page_20.png\n",
            "✅ Saved: OCRimages/page_21.png\n",
            "✅ Saved: OCRimages/page_22.png\n",
            "✅ Saved: OCRimages/page_23.png\n",
            "✅ Saved: OCRimages/page_24.png\n",
            "✅ Saved: OCRimages/page_25.png\n",
            "✅ Saved: OCRimages/page_26.png\n",
            "✅ Saved: OCRimages/page_27.png\n",
            "✅ Saved: OCRimages/page_28.png\n",
            "✅ Saved: OCRimages/page_29.png\n",
            "✅ Saved: OCRimages/page_30.png\n",
            "✅ Saved: OCRimages/page_31.png\n",
            "✅ Saved: OCRimages/page_32.png\n",
            "✅ Saved: OCRimages/page_33.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install tesseract-ocr -y\n",
        "import cv2\n",
        "import pytesseract\n",
        "import re\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Step 1: Preprocess Image for OCR\n",
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
        "    cleaned = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
        "    cleaned = cv2.dilate(cleaned, kernel, iterations=1)  # Improved text clarity\n",
        "    return cleaned\n",
        "\n",
        "# Step 2: OCR for Text Recognition\n",
        "def extract_text(image):\n",
        "    custom_config = r'--oem 3 --psm 6'\n",
        "    detected_text = pytesseract.image_to_string(image, config=custom_config)\n",
        "    return detected_text\n",
        "\n",
        "# Step 3: Regex-Based Tag Extraction\n",
        "def extract_tags(text):\n",
        "    pattern = r'\\b[A-Z0-9]+[-_A-Z0-9\"-]+-[A-Z0-9]+\\b'\n",
        "    return re.findall(pattern, text)\n",
        "\n",
        "# Step 4: Bounding Box Detection for Text-Tag Association\n",
        "def detect_bounding_boxes(image):\n",
        "    data = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)\n",
        "    elements = []\n",
        "    padding = 5  # Added padding for better detection\n",
        "    for i in range(len(data['text'])):\n",
        "        if data['text'][i].strip():\n",
        "            x, y, w, h = data['left'][i] - padding, data['top'][i] - padding, \\\n",
        "                         data['width'][i] + 2 * padding, data['height'][i] + 2 * padding\n",
        "            elements.append({\n",
        "                \"text\": data['text'][i],\n",
        "                \"coordinates\": (x, y, w, h)\n",
        "            })\n",
        "    return elements\n",
        "\n",
        "# Step 5: Pipeline Detection using Contour Mapping\n",
        "def detect_pipelines(image):\n",
        "    edges = cv2.Canny(image, 50, 150, apertureSize=3)\n",
        "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, 80, minLineLength=30, maxLineGap=15)\n",
        "    pipeline_lines = []\n",
        "    if lines is not None:\n",
        "        for line in lines:\n",
        "            x1, y1, x2, y2 = line[0]\n",
        "            pipeline_lines.append(((x1, y1), (x2, y2)))\n",
        "    return pipeline_lines\n",
        "\n",
        "# Step 6: Generate Final Output\n",
        "def generate_output(image_path):\n",
        "    original_img = cv2.imread(image_path)\n",
        "    processed_img = preprocess_image(image_path)\n",
        "    text = extract_text(processed_img)\n",
        "    tags = extract_tags(text)\n",
        "    bounding_boxes = detect_bounding_boxes(processed_img)\n",
        "    pipelines = detect_pipelines(processed_img)\n",
        "\n",
        "    for box in bounding_boxes:\n",
        "        x, y, w, h = box['coordinates']\n",
        "        cv2.rectangle(original_img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "        cv2.putText(original_img, box['text'], (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
        "\n",
        "    annotated_image_path = image_path.replace('.png', '_annotated.png')\n",
        "    cv2.imwrite(annotated_image_path, original_img)\n",
        "\n",
        "    success_status = \"Success\" if tags or bounding_boxes or pipelines else \"Failed\"\n",
        "\n",
        "    output = {\n",
        "        \"Image\": image_path,\n",
        "        \"AnnotatedImage\": annotated_image_path,\n",
        "        \"Status\": success_status,\n",
        "        \"Pipelines\": pipelines,\n",
        "        \"Tags\": tags,\n",
        "        \"BoundingBoxes\": bounding_boxes\n",
        "    }\n",
        "    return output\n",
        "# Example Usage\n",
        "image_folder = 'OCRimages'\n",
        "os.makedirs(image_folder, exist_ok=True)\n",
        "\n",
        "# Create or initialize the JSON file\n",
        "if not os.path.exists('output.json'):\n",
        "    with open('output.json', 'w') as f:\n",
        "        f.write('[\\n')\n",
        "\n",
        "# Process all images in the OCRimages folder and append to JSON\n",
        "with open('output.json', 'a') as f:\n",
        "    for i, image_file in enumerate(os.listdir(image_folder)):\n",
        "        if image_file.endswith('.png'):\n",
        "            image_path = os.path.join(image_folder, image_file)\n",
        "            output = generate_output(image_path)  # Call generate_output and assign to output\n",
        "\n",
        "            if os.path.getsize('output.json') > 2 and i > 0:  # Add comma after first entry\n",
        "                f.write(\",\\n\")\n",
        "\n",
        "            json.dump(output, f, indent=4, default=str)\n",
        "            print(f\"Results for {image_path}: {output['Status']}\")  # Access status from output\n",
        "\n",
        "# Ensure JSON is properly closed\n",
        "with open('output.json', 'a') as f:\n",
        "    f.write(\"\\n]\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTzI0bxwsk5Z",
        "outputId": "a9388100-e7a5-4a74-f48b-314ea5d52a7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "Results for OCRimages/page_2_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_31.png: Success\n",
            "Results for OCRimages/page_1_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_29_annotated.png: Success\n",
            "Results for OCRimages/page_25_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_21_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_6_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_28_annotated.png: Success\n",
            "Results for OCRimages/page_5_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_11_annotated.png: Success\n",
            "Results for OCRimages/page_7.png: Success\n",
            "Results for OCRimages/page_14.png: Success\n",
            "Results for OCRimages/page_12_annotated.png: Success\n",
            "Results for OCRimages/page_27_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_31_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_6_annotated.png: Success\n",
            "Results for OCRimages/page_10.png: Success\n",
            "Results for OCRimages/page_22.png: Success\n",
            "Results for OCRimages/page_32.png: Success\n",
            "Results for OCRimages/page_31_annotated.png: Success\n",
            "Results for OCRimages/page_4_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_6.png: Success\n",
            "Results for OCRimages/page_25_annotated.png: Success\n",
            "Results for OCRimages/page_20_annotated.png: Success\n",
            "Results for OCRimages/page_31_annotated_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_4.png: Success\n",
            "Results for OCRimages/page_32_annotated.png: Success\n",
            "Results for OCRimages/page_16_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_21_annotated.png: Success\n",
            "Results for OCRimages/page_13_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_16.png: Success\n",
            "Results for OCRimages/page_8.png: Success\n",
            "Results for OCRimages/page_2_annotated.png: Success\n",
            "Results for OCRimages/page_28.png: Success\n",
            "Results for OCRimages/page_12.png: Success\n",
            "Results for OCRimages/page_7_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_23_annotated.png: Success\n",
            "Results for OCRimages/page_8_annotated.png: Success\n",
            "Results for OCRimages/page_16_annotated.png: Success\n",
            "Results for OCRimages/page_9_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_9.png: Success\n",
            "Results for OCRimages/page_4_annotated.png: Success\n",
            "Results for OCRimages/page_11.png: Success\n",
            "Results for OCRimages/page_3.png: Success\n",
            "Results for OCRimages/page_30_annotated.png: Success\n",
            "Results for OCRimages/page_18.png: Success\n",
            "Results for OCRimages/page_8_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_26.png: Success\n",
            "Results for OCRimages/page_24_annotated.png: Success\n",
            "Results for OCRimages/page_28_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_21.png: Success\n",
            "Results for OCRimages/page_10_annotated.png: Success\n",
            "Results for OCRimages/page_15.png: Success\n",
            "Results for OCRimages/page_17.png: Success\n",
            "Results for OCRimages/page_30.png: Success\n",
            "Results for OCRimages/page_23_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_33.png: Success\n",
            "Results for OCRimages/page_24_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_19_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_3_annotated.png: Success\n",
            "Results for OCRimages/page_26_annotated.png: Success\n",
            "Results for OCRimages/page_22_annotated.png: Success\n",
            "Results for OCRimages/page_19_annotated.png: Success\n",
            "Results for OCRimages/page_29_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_26_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_3_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_13_annotated.png: Success\n",
            "Results for OCRimages/page_1.png: Success\n",
            "Results for OCRimages/page_5.png: Success\n",
            "Results for OCRimages/page_1_annotated.png: Success\n",
            "Results for OCRimages/page_23.png: Success\n",
            "Results for OCRimages/page_20_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_20.png: Success\n",
            "Results for OCRimages/page_5_annotated.png: Success\n",
            "Results for OCRimages/page_33_annotated.png: Success\n",
            "Results for OCRimages/page_9_annotated.png: Success\n",
            "Results for OCRimages/page_27.png: Success\n",
            "Results for OCRimages/page_15_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_18_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_7_annotated.png: Success\n",
            "Results for OCRimages/page_10_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_24.png: Success\n",
            "Results for OCRimages/page_18_annotated.png: Success\n",
            "Results for OCRimages/page_32_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_33_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_17_annotated.png: Success\n",
            "Results for OCRimages/page_2.png: Success\n",
            "Results for OCRimages/page_27_annotated.png: Success\n",
            "Results for OCRimages/page_14_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_22_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_11_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_12_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_13.png: Success\n",
            "Results for OCRimages/page_29.png: Success\n",
            "Results for OCRimages/page_17_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_30_annotated_annotated.png: Success\n",
            "Results for OCRimages/page_19.png: Success\n",
            "Results for OCRimages/page_25.png: Success\n",
            "Results for OCRimages/page_15_annotated.png: Success\n",
            "Results for OCRimages/page_14_annotated.png: Success\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install tesseract-ocr -y\n",
        "import cv2\n",
        "import pytesseract\n",
        "import re\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Step 1: Preprocess Image for OCR\n",
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
        "    return thresh\n",
        "\n",
        "# Step 2: Region-Based Segmentation\n",
        "def segment_regions(image):\n",
        "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(image, connectivity=8)\n",
        "    regions = []\n",
        "    for i in range(1, num_labels):\n",
        "        x, y, w, h, area = stats[i]\n",
        "        if area > 100:  # Filter out small noise\n",
        "            region = image[y:y + h, x:x + w]\n",
        "            regions.append((region, (x, y, w, h)))\n",
        "    return regions\n",
        "\n",
        "# Step 3: OCR for Text Recognition\n",
        "def extract_text(region):\n",
        "    custom_config = r'--oem 3 --psm 6'\n",
        "    return pytesseract.image_to_string(region, config=custom_config)\n",
        "\n",
        "# Step 4: Tag Extraction using Regex\n",
        "def extract_tags(text):\n",
        "    pattern = r'\\b[A-Z0-9]+[-_A-Z0-9\"-]+-[A-Z0-9]+\\b'\n",
        "    return re.findall(pattern, text)\n",
        "\n",
        "# Step 5: Annotated Output Generation\n",
        "def generate_output(image_path):\n",
        "    original_img = cv2.imread(image_path)\n",
        "    processed_img = preprocess_image(image_path)\n",
        "    regions = segment_regions(processed_img)\n",
        "\n",
        "    tags = []\n",
        "    bounding_boxes = []\n",
        "\n",
        "    for region, (x, y, w, h) in regions:\n",
        "        text = extract_text(region)\n",
        "        detected_tags = extract_tags(text)\n",
        "        tags.extend(detected_tags)\n",
        "\n",
        "        if text.strip():\n",
        "            bounding_boxes.append({\"text\": text.strip(), \"coordinates\": (x, y, w, h)})\n",
        "            cv2.rectangle(original_img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "            cv2.putText(original_img, text.strip(), (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
        "\n",
        "    annotated_image_path = image_path.replace('.png', '_annotated.png')\n",
        "    cv2.imwrite(annotated_image_path, original_img)\n",
        "\n",
        "    success_status = \"Success\" if tags or bounding_boxes else \"Failed\"\n",
        "\n",
        "    output = {\n",
        "        \"Image\": image_path,\n",
        "        \"AnnotatedImage\": annotated_image_path,\n",
        "        \"Status\": success_status,\n",
        "        \"Tags\": tags,\n",
        "        \"BoundingBoxes\": bounding_boxes\n",
        "    }\n",
        "    return output\n",
        "\n",
        "# Example Usage\n",
        "image_folder = 'OCRimages'\n",
        "os.makedirs(image_folder, exist_ok=True)\n",
        "\n",
        "if not os.path.exists('output.json'):\n",
        "    with open('output.json', 'w') as f:\n",
        "        f.write('[\\n')\n",
        "\n",
        "with open('output.json', 'a') as f:\n",
        "    for i, image_file in enumerate(os.listdir(image_folder)):\n",
        "        if image_file.endswith('.png'):\n",
        "            image_path = os.path.join(image_folder, image_file)\n",
        "            output = generate_output(image_path)\n",
        "\n",
        "            if os.path.getsize('output.json') > 2 and i > 0:\n",
        "                f.write(\",\\n\")\n",
        "\n",
        "            json.dump(output, f, indent=4, default=str)\n",
        "            print(f\"Results for {image_path}: {output['Status']}\")\n",
        "\n",
        "with open('output.json', 'a') as f:\n",
        "    f.write(\"\\n]\")\n"
      ],
      "metadata": {
        "id": "Qmo-jJJQJICL",
        "outputId": "9a18c3da-0472-4bee-9424-74e46d38b459",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 2s (2,699 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 124977 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Results for OCRimages/page_31.png: Success\n",
            "Results for OCRimages/page_7.png: Success\n",
            "Results for OCRimages/page_14.png: Success\n",
            "Results for OCRimages/page_10.png: Success\n",
            "Results for OCRimages/page_22.png: Success\n",
            "Results for OCRimages/page_32.png: Success\n",
            "Results for OCRimages/page_6.png: Success\n",
            "Results for OCRimages/page_4.png: Success\n",
            "Results for OCRimages/page_16.png: Success\n",
            "Results for OCRimages/page_8.png: Success\n",
            "Results for OCRimages/page_28.png: Success\n",
            "Results for OCRimages/page_12.png: Success\n",
            "Results for OCRimages/page_9.png: Success\n",
            "Results for OCRimages/page_11.png: Success\n",
            "Results for OCRimages/page_3.png: Success\n",
            "Results for OCRimages/page_18.png: Success\n",
            "Results for OCRimages/page_26.png: Success\n",
            "Results for OCRimages/page_21.png: Success\n",
            "Results for OCRimages/page_15.png: Success\n",
            "Results for OCRimages/page_17.png: Success\n",
            "Results for OCRimages/page_30.png: Success\n",
            "Results for OCRimages/page_33.png: Success\n",
            "Results for OCRimages/page_1.png: Success\n",
            "Results for OCRimages/page_5.png: Success\n",
            "Results for OCRimages/page_23.png: Success\n",
            "Results for OCRimages/page_20.png: Success\n",
            "Results for OCRimages/page_27.png: Success\n",
            "Results for OCRimages/page_24.png: Success\n",
            "Results for OCRimages/page_2.png: Success\n",
            "Results for OCRimages/page_13.png: Success\n",
            "Results for OCRimages/page_29.png: Success\n",
            "Results for OCRimages/page_19.png: Success\n",
            "Results for OCRimages/page_25.png: Success\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "import re\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Step 1: Preprocess Image for OCR\n",
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
        "    cleaned = cv2.medianBlur(thresh, 3)\n",
        "    preprocessed_image_path = image_path.replace('.png', '_preprocessed.png')\n",
        "    cv2.imwrite(preprocessed_image_path, cleaned)\n",
        "    return cleaned, preprocessed_image_path\n",
        "\n",
        "# Step 2: Region-Based Segmentation\n",
        "def segment_regions(image):\n",
        "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(image, connectivity=8)\n",
        "    regions = []\n",
        "    for i in range(1, num_labels):\n",
        "        x, y, w, h, area = stats[i]\n",
        "        if area > 100:  # Filter out small noise\n",
        "            region = image[y:y + h, x:x + w]\n",
        "            regions.append((region, (x, y, w, h)))\n",
        "    return regions\n",
        "\n",
        "# Step 3: OCR for Text Recognition\n",
        "def extract_text(region):\n",
        "    custom_config = r'--oem 3 --psm 6'\n",
        "    return pytesseract.image_to_string(region, config=custom_config)\n",
        "\n",
        "# Step 4: Tag Extraction using Regex\n",
        "def extract_tags(text):\n",
        "    pattern = r'\\b[A-Z0-9]+[-_A-Z0-9\"-]+-[A-Z0-9]+\\b'\n",
        "    return re.findall(pattern, text)\n",
        "\n",
        "# Step 5: Pipeline Detection using Edge/Shape Detection\n",
        "def detect_pipelines(image):\n",
        "    edges = cv2.Canny(image, 50, 150, apertureSize=3)\n",
        "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 80, minLineLength=30, maxLineGap=15)\n",
        "    pipeline_lines = []\n",
        "    if lines is not None:\n",
        "        for line in lines:\n",
        "            x1, y1, x2, y2 = line[0]\n",
        "            pipeline_lines.append(((x1, y1), (x2, y2)))\n",
        "    return pipeline_lines\n",
        "\n",
        "# Step 6: Annotated Output Generation\n",
        "def generate_output(image_path):\n",
        "    original_img = cv2.imread(image_path)\n",
        "    processed_img, preprocessed_image_path = preprocess_image(image_path)\n",
        "    regions = segment_regions(processed_img)\n",
        "    pipelines = detect_pipelines(original_img)\n",
        "\n",
        "    tags = []\n",
        "    bounding_boxes = []\n",
        "\n",
        "    for region, (x, y, w, h) in regions:\n",
        "        text = extract_text(region)\n",
        "        detected_tags = extract_tags(text)\n",
        "        tags.extend(detected_tags)\n",
        "\n",
        "        if text.strip():\n",
        "            bounding_boxes.append({\"text\": text.strip(), \"coordinates\": (x, y, w, h)})\n",
        "            cv2.rectangle(original_img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "            cv2.putText(original_img, text.strip(), (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
        "\n",
        "    for (x1, y1), (x2, y2) in pipelines:\n",
        "        cv2.line(original_img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "\n",
        "    annotated_image_path = image_path.replace('.png', '_annotated.png')\n",
        "    cv2.imwrite(annotated_image_path, original_img)\n",
        "\n",
        "    success_status = \"Success\" if tags or bounding_boxes else \"Failed\"\n",
        "\n",
        "    output = {\n",
        "        \"Image\": image_path,\n",
        "        \"PreprocessedImage\": preprocessed_image_path,\n",
        "        \"AnnotatedImage\": annotated_image_path,\n",
        "        \"Status\": success_status,\n",
        "        \"Pipelines\": pipelines,\n",
        "        \"Tags\": tags,\n",
        "        \"BoundingBoxes\": bounding_boxes\n",
        "    }\n",
        "    return output\n",
        "\n",
        "# Example Usage\n",
        "image_folder = 'OCRimages'\n",
        "os.makedirs(image_folder, exist_ok=True)\n",
        "\n",
        "all_outputs = []\n",
        "for image_file in os.listdir(image_folder):\n",
        "    if image_file.endswith('.png'):\n",
        "        image_path = os.path.join(image_folder, image_file)\n",
        "        output = generate_output(image_path)\n",
        "        all_outputs.append(output)\n",
        "        print(f\"Results for {image_path}: {output['Status']}\")\n",
        "\n",
        "with open('output.json', 'w') as f:\n",
        "    json.dump(all_outputs, f, indent=4, default=str)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zwu9FHv9oVVO",
        "outputId": "f2bb1802-157a-4509-b3f4-c29da4f7a4b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for OCRimages/page_31.png: Success\n",
            "Results for OCRimages/page_29_annotated.png: Success\n",
            "Results for OCRimages/page_28_annotated.png: Success\n",
            "Results for OCRimages/page_11_annotated.png: Success\n",
            "Results for OCRimages/page_7.png: Success\n",
            "Results for OCRimages/page_14.png: Success\n",
            "Results for OCRimages/page_12_annotated.png: Success\n",
            "Results for OCRimages/page_6_annotated.png: Success\n",
            "Results for OCRimages/page_10.png: Success\n",
            "Results for OCRimages/page_22.png: Success\n",
            "Results for OCRimages/page_32.png: Success\n",
            "Results for OCRimages/page_31_annotated.png: Success\n",
            "Results for OCRimages/page_6.png: Success\n",
            "Results for OCRimages/page_25_annotated.png: Success\n",
            "Results for OCRimages/page_20_annotated.png: Success\n",
            "Results for OCRimages/page_4.png: Success\n",
            "Results for OCRimages/page_32_annotated.png: Success\n",
            "Results for OCRimages/page_21_annotated.png: Success\n",
            "Results for OCRimages/page_16.png: Success\n",
            "Results for OCRimages/page_8.png: Success\n",
            "Results for OCRimages/page_2_annotated.png: Success\n",
            "Results for OCRimages/page_28.png: Success\n",
            "Results for OCRimages/page_12.png: Success\n",
            "Results for OCRimages/page_23_annotated.png: Success\n",
            "Results for OCRimages/page_8_annotated.png: Success\n",
            "Results for OCRimages/page_16_annotated.png: Success\n",
            "Results for OCRimages/page_9.png: Success\n",
            "Results for OCRimages/page_4_annotated.png: Success\n",
            "Results for OCRimages/page_11.png: Success\n",
            "Results for OCRimages/page_3.png: Success\n",
            "Results for OCRimages/page_30_annotated.png: Success\n",
            "Results for OCRimages/page_18.png: Success\n",
            "Results for OCRimages/page_26.png: Success\n",
            "Results for OCRimages/page_24_annotated.png: Success\n",
            "Results for OCRimages/page_21.png: Success\n",
            "Results for OCRimages/page_10_annotated.png: Success\n",
            "Results for OCRimages/page_15.png: Success\n",
            "Results for OCRimages/page_17.png: Success\n",
            "Results for OCRimages/page_30.png: Success\n",
            "Results for OCRimages/page_33.png: Success\n",
            "Results for OCRimages/page_3_annotated.png: Success\n",
            "Results for OCRimages/page_26_annotated.png: Success\n",
            "Results for OCRimages/page_22_annotated.png: Success\n",
            "Results for OCRimages/page_19_annotated.png: Success\n",
            "Results for OCRimages/page_13_annotated.png: Success\n",
            "Results for OCRimages/page_1.png: Success\n",
            "Results for OCRimages/page_5.png: Success\n",
            "Results for OCRimages/page_1_annotated.png: Success\n",
            "Results for OCRimages/page_23.png: Success\n",
            "Results for OCRimages/page_20.png: Success\n",
            "Results for OCRimages/page_5_annotated.png: Success\n",
            "Results for OCRimages/page_33_annotated.png: Success\n",
            "Results for OCRimages/page_9_annotated.png: Success\n",
            "Results for OCRimages/page_27.png: Success\n",
            "Results for OCRimages/page_7_annotated.png: Success\n",
            "Results for OCRimages/page_24.png: Success\n",
            "Results for OCRimages/page_18_annotated.png: Success\n",
            "Results for OCRimages/page_17_annotated.png: Success\n",
            "Results for OCRimages/page_2.png: Success\n",
            "Results for OCRimages/page_27_annotated.png: Success\n",
            "Results for OCRimages/page_13.png: Success\n",
            "Results for OCRimages/page_29.png: Success\n",
            "Results for OCRimages/page_19.png: Success\n",
            "Results for OCRimages/page_25.png: Success\n",
            "Results for OCRimages/page_15_annotated.png: Success\n",
            "Results for OCRimages/page_14_annotated.png: Success\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Zip the OCRimages folder\n",
        "shutil.make_archive('OCRimages', 'zip', 'OCRimages')\n",
        "\n",
        "# Download the zipped folder\n",
        "files.download('OCRimages.zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "CT6mJSyWw_PJ",
        "outputId": "24fd4b4f-25b3-4a8e-a55f-0d896baf914f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9f163f7c-2e55-4eba-8d3c-33337858ac10\", \"OCRimages.zip\", 39394354)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Step 1: Extract Annotated Images from ZIP and Convert to TXT\n",
        "def extract_annotated_and_convert(zip_path):\n",
        "    # Extract ZIP contents\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall('OCRimages')\n",
        "\n",
        "    # Create folder to store .txt files\n",
        "    txt_folder = 'OCR_txt_files'\n",
        "    os.makedirs(txt_folder, exist_ok=True)\n",
        "\n",
        "    # Process each annotated image\n",
        "    for image_file in os.listdir('OCRimages'):\n",
        "        if '_annotated.png' in image_file:\n",
        "            image_path = os.path.join('OCRimages', image_file)\n",
        "\n",
        "            # OCR text extraction\n",
        "            text = pytesseract.image_to_string(cv2.imread(image_path))\n",
        "\n",
        "            # Save text as .txt file\n",
        "            text_file_path = os.path.join(txt_folder, image_file.replace('.png', '.txt'))\n",
        "            with open(text_file_path, 'w') as txt_file:\n",
        "                txt_file.write(text)\n",
        "\n",
        "            print(f'Converted {image_file} to {text_file_path}')\n",
        "\n",
        "    # Create a ZIP archive of all .txt files\n",
        "    zip_output = 'OCR_text_files.zip'\n",
        "    shutil.make_archive('OCR_text_files', 'zip', txt_folder)\n",
        "    files.download(zip_output)\n",
        "\n",
        "# Example Usage\n",
        "extract_annotated_and_convert('/content/OCRimages.zip')\n"
      ],
      "metadata": {
        "id": "ZcU9-glEyN2U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8f5bedf6-e78f-4f61-b9c2-3f3274aee0e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted page_2_annotated_annotated.png to OCR_txt_files/page_2_annotated_annotated.txt\n",
            "Converted page_1_annotated_annotated.png to OCR_txt_files/page_1_annotated_annotated.txt\n",
            "Converted page_29_annotated.png to OCR_txt_files/page_29_annotated.txt\n",
            "Converted page_25_annotated_annotated.png to OCR_txt_files/page_25_annotated_annotated.txt\n",
            "Converted page_21_annotated_annotated.png to OCR_txt_files/page_21_annotated_annotated.txt\n",
            "Converted page_6_annotated_annotated.png to OCR_txt_files/page_6_annotated_annotated.txt\n",
            "Converted page_28_annotated.png to OCR_txt_files/page_28_annotated.txt\n",
            "Converted page_5_annotated_annotated.png to OCR_txt_files/page_5_annotated_annotated.txt\n",
            "Converted page_11_annotated.png to OCR_txt_files/page_11_annotated.txt\n",
            "Converted page_12_annotated.png to OCR_txt_files/page_12_annotated.txt\n",
            "Converted page_27_annotated_annotated.png to OCR_txt_files/page_27_annotated_annotated.txt\n",
            "Converted page_31_annotated_annotated.png to OCR_txt_files/page_31_annotated_annotated.txt\n",
            "Converted page_6_annotated.png to OCR_txt_files/page_6_annotated.txt\n",
            "Converted page_31_annotated.png to OCR_txt_files/page_31_annotated.txt\n",
            "Converted page_4_annotated_annotated.png to OCR_txt_files/page_4_annotated_annotated.txt\n",
            "Converted page_25_annotated.png to OCR_txt_files/page_25_annotated.txt\n",
            "Converted page_20_annotated.png to OCR_txt_files/page_20_annotated.txt\n",
            "Converted page_32_annotated.png to OCR_txt_files/page_32_annotated.txt\n",
            "Converted page_16_annotated_annotated.png to OCR_txt_files/page_16_annotated_annotated.txt\n",
            "Converted page_21_annotated.png to OCR_txt_files/page_21_annotated.txt\n",
            "Converted page_13_annotated_annotated.png to OCR_txt_files/page_13_annotated_annotated.txt\n",
            "Converted page_2_annotated.png to OCR_txt_files/page_2_annotated.txt\n",
            "Converted page_7_annotated_annotated.png to OCR_txt_files/page_7_annotated_annotated.txt\n",
            "Converted page_23_annotated.png to OCR_txt_files/page_23_annotated.txt\n",
            "Converted page_8_annotated.png to OCR_txt_files/page_8_annotated.txt\n",
            "Converted page_16_annotated.png to OCR_txt_files/page_16_annotated.txt\n",
            "Converted page_9_annotated_annotated.png to OCR_txt_files/page_9_annotated_annotated.txt\n",
            "Converted page_4_annotated.png to OCR_txt_files/page_4_annotated.txt\n",
            "Converted page_30_annotated.png to OCR_txt_files/page_30_annotated.txt\n",
            "Converted page_8_annotated_annotated.png to OCR_txt_files/page_8_annotated_annotated.txt\n",
            "Converted page_24_annotated.png to OCR_txt_files/page_24_annotated.txt\n",
            "Converted page_28_annotated_annotated.png to OCR_txt_files/page_28_annotated_annotated.txt\n",
            "Converted page_10_annotated.png to OCR_txt_files/page_10_annotated.txt\n",
            "Converted page_23_annotated_annotated.png to OCR_txt_files/page_23_annotated_annotated.txt\n",
            "Converted page_24_annotated_annotated.png to OCR_txt_files/page_24_annotated_annotated.txt\n",
            "Converted page_19_annotated_annotated.png to OCR_txt_files/page_19_annotated_annotated.txt\n",
            "Converted page_3_annotated.png to OCR_txt_files/page_3_annotated.txt\n",
            "Converted page_26_annotated.png to OCR_txt_files/page_26_annotated.txt\n",
            "Converted page_22_annotated.png to OCR_txt_files/page_22_annotated.txt\n",
            "Converted page_19_annotated.png to OCR_txt_files/page_19_annotated.txt\n",
            "Converted page_29_annotated_annotated.png to OCR_txt_files/page_29_annotated_annotated.txt\n",
            "Converted page_26_annotated_annotated.png to OCR_txt_files/page_26_annotated_annotated.txt\n",
            "Converted page_3_annotated_annotated.png to OCR_txt_files/page_3_annotated_annotated.txt\n",
            "Converted page_13_annotated.png to OCR_txt_files/page_13_annotated.txt\n",
            "Converted page_1_annotated.png to OCR_txt_files/page_1_annotated.txt\n",
            "Converted page_20_annotated_annotated.png to OCR_txt_files/page_20_annotated_annotated.txt\n",
            "Converted page_5_annotated.png to OCR_txt_files/page_5_annotated.txt\n",
            "Converted page_33_annotated.png to OCR_txt_files/page_33_annotated.txt\n",
            "Converted page_9_annotated.png to OCR_txt_files/page_9_annotated.txt\n",
            "Converted page_15_annotated_annotated.png to OCR_txt_files/page_15_annotated_annotated.txt\n",
            "Converted page_18_annotated_annotated.png to OCR_txt_files/page_18_annotated_annotated.txt\n",
            "Converted page_7_annotated.png to OCR_txt_files/page_7_annotated.txt\n",
            "Converted page_10_annotated_annotated.png to OCR_txt_files/page_10_annotated_annotated.txt\n",
            "Converted page_18_annotated.png to OCR_txt_files/page_18_annotated.txt\n",
            "Converted page_32_annotated_annotated.png to OCR_txt_files/page_32_annotated_annotated.txt\n",
            "Converted page_33_annotated_annotated.png to OCR_txt_files/page_33_annotated_annotated.txt\n",
            "Converted page_17_annotated.png to OCR_txt_files/page_17_annotated.txt\n",
            "Converted page_27_annotated.png to OCR_txt_files/page_27_annotated.txt\n",
            "Converted page_14_annotated_annotated.png to OCR_txt_files/page_14_annotated_annotated.txt\n",
            "Converted page_22_annotated_annotated.png to OCR_txt_files/page_22_annotated_annotated.txt\n",
            "Converted page_11_annotated_annotated.png to OCR_txt_files/page_11_annotated_annotated.txt\n",
            "Converted page_12_annotated_annotated.png to OCR_txt_files/page_12_annotated_annotated.txt\n",
            "Converted page_17_annotated_annotated.png to OCR_txt_files/page_17_annotated_annotated.txt\n",
            "Converted page_30_annotated_annotated.png to OCR_txt_files/page_30_annotated_annotated.txt\n",
            "Converted page_15_annotated.png to OCR_txt_files/page_15_annotated.txt\n",
            "Converted page_14_annotated.png to OCR_txt_files/page_14_annotated.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a5a2b8be-7804-40d4-be6a-6eb944485bc5\", \"OCR_text_files.zip\", 14727)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "# Step 1: Extract and Organize Files\n",
        "def extract_and_organize(zip_path):\n",
        "    # Extract ZIP contents\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall('OCRimages')\n",
        "\n",
        "    # Create folders for each category\n",
        "    folder_structure = {\n",
        "        'preprocessed': 'Preprocessed_Images',\n",
        "        'original': 'Original_Images',\n",
        "        'annotated': 'Annotated_Images',\n",
        "        'annotated_annotated': 'Annotated_Annotated_Images',\n",
        "    }\n",
        "\n",
        "    for folder in folder_structure.values():\n",
        "        os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "    # Copy files to respective folders\n",
        "    for image_file in os.listdir('OCRimages'):\n",
        "        if image_file.endswith('.png'):\n",
        "            source_path = os.path.join('OCRimages', image_file)\n",
        "\n",
        "            if 'preprocessed' in image_file:\n",
        "                shutil.copy(source_path, os.path.join(folder_structure['preprocessed'], image_file))\n",
        "            elif '_annotated_annotated' in image_file:\n",
        "                shutil.copy(source_path, os.path.join(folder_structure['annotated_annotated'], image_file))\n",
        "            elif '_annotated' in image_file:\n",
        "                shutil.copy(source_path, os.path.join(folder_structure['annotated'], image_file))\n",
        "            else:\n",
        "                shutil.copy(source_path, os.path.join(folder_structure['original'], image_file))\n",
        "\n",
        "    print(\"Files have been successfully organized into respective folders.\")\n",
        "\n",
        "# Example Usage\n",
        "extract_and_organize('/content/OCRimages.zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OviN8SAX3mTB",
        "outputId": "804c55ab-1f77-4638-a46d-f45bead04c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files have been successfully organized into respective folders.\n"
          ]
        }
      ]
    }
  ]
}